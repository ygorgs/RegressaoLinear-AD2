---
title: "Problema 3.2"
author: "Ygor Santos"
date: "01 de abril de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Bibliotecas Usadas
library(gmodels)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(dplyr)
library(caret)
library(lars)
library(elasticnet)
```

## Objetivo da Análise

  Antígeno Prostático Específico (PSA) é uma substância produzida pelas células da glândula prostática. O PSA é encontrado principalmente no sêmen, mas uma pequena quantidade é também encontrada no sangue. A maioria dos homens saudáveis têm níveis menores de 4ng/ml de sangue. A chance de um homem desenvolver câncer de próstata aumenta proporcionalmente com o aumento do nível de PSA (ver <http://www.oncoguia.org.br/conteudo/antigeno-prostatico-especifico-psa-no-diagnostico-do-cancer-de-prostata/1202/289/>).

  A atividade para este checkpoint será prever o nível do PSA em pacientes através de uma regressão linear.


###Leitura dos dados

```{r dados}

dados <- read.table("dados.txt", header=T, dec=".")

summary(dados)

```
  Os dados utilizados neste problema são referentes a exames em pacientes homens afim de identificar sintomas de câncer de prostata. O dataset é composto por dez variáveis, onde uma delas (psa) será considerada nossa variável resposta. Nosso objetivo final será predizer a variável psa a partir dos preditores disponíveis.

  Como campos do dataset, temos:
  ------
   vol: volume do câncer 
   weight:  peso do paciente
   age: idade do paciente
   bph: hiperplasia prostática benigna
   svi: invasão das vesículas seminais
   cp: penetração capsular
   gleason: escore Gleason
   pgg45: percentagem escore Gleason 4 ou 5
   psa: antígeno específico da próstata (esta é a variável resposta).

Obs.: A variável ‘train’ será utilizada para divisão do dataset em treino e teste.
Obs2.: Observe que foi aplicada a função log em algumas variáveis.  


###Particionamento dos dados

Vamos separar os dados para treino e testes de acordo com a váriavel train.

```{r particionamento}

#dados de treino
dados_treino <- filter(dados, train == TRUE)

#dados de teste
dados_teste <- filter(dados, train == FALSE)

```

###Analise descritiva dos dados

Abaixo estão os scatter plots mostrando a dispersão dos valores de cada váriavel com váriavel psa (que será a váriavel resposta):

```{r analiseDescritiva, echo=FALSE}

#Criando gráficos
plot_vol <- qplot(dados$lcavol, dados$lpsa, xlab = "lcavol", ylab ="PSA")
plot_weight <- qplot(dados$lweight, dados$lpsa, xlab = "lweight", ylab ="PSA")
plot_age <- qplot(dados$age, dados$lpsa, xlab = "age", ylab ="PSA")
plot_bph <- qplot(dados$lbph, dados$lpsa, xlab = "lbph", ylab ="PSA")
plot_svi <- qplot(dados$svi, dados$lpsa, xlab = "svi", ylab ="PSA")
plot_cp <- qplot(dados$lcp, dados$lpsa, xlab = "lcp", ylab ="PSA")
plot_gleason <- qplot(dados$gleason, dados$lpsa, xlab = "gleason", ylab ="PSA")
plot_pgg45 <- qplot(dados$pgg45, dados$lpsa, xlab = "pgg45", ylab ="PSA")

#Plotando quatro deles
grid.arrange(plot_vol, plot_weight, plot_age, plot_bph, ncol=2, nrow=2)

#Plotando quatro deles 
grid.arrange(plot_svi, plot_cp, plot_gleason, plot_pgg45, ncol=2, nrow=2)

```

###Analise de correlação das variáveis

Abaixo estão as correlações entre as váriaveis numéricas presente nos dados. 

```{r analiseCorrelacao1}

nums <- sapply(dados, is.numeric)
cor(dados[,nums])

```

Graficamente:

```{r analiseCorrelacao2, echo=FALSE}

correlations <- cor(dados[,nums])
corrplot(correlations, order="hclust", type="lower")

```
Com isso, nós podemos visualizar o nivel correlação da variavel lpsa com as demais preditores e escolher os preditores que serão usados no modelo. lcavol possue uma correlação positiva forte com a variável resposta (lpsa) por isso ela será importante no modelo, serão usados também as variáveis svi e lcp.


###Conclusões das analises

#####**1. Há evidência de relação entre os preditores e a variável alvo?**
Sim, de acordo com o gráfico de correlações, vemos que todos os preditores possuem algum tipo de relação com a variável resposta ipsa.

#####**2. Havendo relação, quão forte é essa relação?**
O nível dessa relação vária de acordo com o preditor. As variáveis 'iweight', 'ibph' e 'glesson' possuem uma relação fraca com a variável ipsa; 'svi e 'icp' possuem um releção moderada e 'lcavol' possue uma relação forte (não tão forte quanto o ideal).

#####**3.  Que variável parece contribuir mais?**
'lcavol' é a que mais parece que irá contribuir com o modelo por causa da sua correlação.

#####**4. A relação sugere um modelo de regressão linear?**
Sim, pois há algumas váriaveis que possuem uma boa relação com a variável a variável resposta e que podem ser usadas no modelo.

##Regressão Linear

###Treinando o modelo

A variáveis de interesse que escolhi foram lcavol, svi e lcp. Para o treinamento do modelo, serão usados os dados de treino (dados_treino).

```{r regressao_linear}

#obtendo a regressão linear
reg_linear <- lm(lpsa ~ lcavol+svi+lcp, data = dados_treino)

#sumário do modelo
summary(reg_linear)

```

###Realizando previsões

Para obter as previsões do modelo, serão usados os dados de teste (dados_teste)

```{r predicoes}

#predições
predicoes <- predict(reg_linear, select(dados_teste,lcavol, svi, lcp))

#dataframe com as predições
lm_predicoes <- data.frame(pred = predicoes, obs = dados_teste$lpsa)

```

Gráfico de valores observados versus valores previstos:

```{r graficoDiagnostico1}

ggplot(lm_predicoes, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "blue") + ggtitle("Observados X Previstos (validação)")

```

###Resíduos na validação

Obtendo os resíduos.

```{r residuos}

#resíduos
residuos = dados_teste$lpsa - predicoes

```

Gráfico de predições versus resíduous:

```{r graficoDiagnostico2}

qplot(predicoes, residuos, ylab = "Resíduos", xlab = "Predições") +
  geom_hline(yintercept = 0, color='blue') + ggtitle("Resíduos x Predição")

```

###Calculando o RMSE

```{r rmse}

#mean squared error
RMSE(predicoes, dados_teste$lpsa)

```

##Modelo LASSO

###Seleção de preditores
A seleção dos preditores que irão ser utilizados no modelo LASSO será feita através de validação cruzada.

```{r LASSO}

lasso.fit <- train(lpsa ~ ., data=select(dados_treino, lcavol, lweight, age, lbph, svi, lcp, gleason, pgg45, lpsa), method='lasso', metric='RMSE',tuneLength=10)

plot(lasso.fit)

lasso.fit

```

###Importância das variáveis para o modelo LASSO

```{r variaveisLASSO}

plot(varImp(lasso.fit))

```

###Realizando previsões com o modelo LASSO

```{r previsoesLASSO}

lasso_predicoes <- predict(lasso.fit, select(dados_teste,lcavol, lweight, age, lbph, svi, lcp, gleason, pgg45))

la_predicoes <- data.frame(pred = lasso_predicoes, obs = dados_teste$lpsa)

ggplot(la_predicoes, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "blue") + ggtitle("Observados X Previstos (LASSO)")

```

###Calculando o RMSE no modelo LASSO

```{r rmseLASSO}

#mean squared error
RMSE(lasso_predicoes, dados_teste$lpsa)

```

##Comparando os modelos

Agora, iremos comparar os resultados obtidos entre os dois modelos utilizando o RMSE como métrica de avaliação

```{r compare}

lm_predicoes$model <- "RL"
la_predicoes$model <- "LASSO"

compare <- rbind(lm_predicoes, la_predicoes)

ggplot(compare, aes(x = pred, y = obs)) + 
  geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + 
  facet_grid(. ~ model) + 
  geom_abline() +
  ggtitle("Observado x Previsão (validação)")

#RMSE - Regressão Linear
RMSE(predicoes, dados_teste$lpsa)

#RMSE - Modelo LASSO
RMSE(lasso_predicoes, dados_teste$lpsa)

```

###Conclusão
Analisando os resultados apresentados pelos dois modelos, vemos que ambos se ajustaram bem aos valores de testes usados para fazer previsões. Os RMSE's produzidos pelos dois modelos são baixos e praticamente iguais. Isso nos mostra que os modelos não são tão diferentes um do outro, pois produzem resultados semelhantes.

---

